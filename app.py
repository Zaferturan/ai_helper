import streamlit as st
import requests
import json
import os
from datetime import datetime

# Backend URL
BACKEND_URL = "http://localhost:8000/api/v1"

# Sayfa konfigÃ¼rasyonu
st.set_page_config(
    page_title="AI Helper - Bursa NilÃ¼fer Belediyesi",
    page_icon="icon.ico",
    layout="wide"
)

# CSS stilleri
st.markdown("""
<style>
    .main .block-container {
        padding-top: 2rem;
        padding-bottom: 2rem;
    }
    .stButton > button {
        width: 100%;
        margin-top: 1rem;
        background-color: #50c2eb !important;
        border-color: #50c2eb !important;
        box-shadow: 0 4px 8px rgba(0,0,0,0.1) !important;
    }
    .stButton > button:hover {
        background-color: #3ba8d1 !important;
        border-color: #3ba8d1 !important;
        box-shadow: 0 6px 12px rgba(0,0,0,0.15) !important;
    }
    .response-box {
        background-color: #f0f2f6;
        padding: 1rem;
        border-radius: 0.5rem;
        margin: 1rem 0;
        box-shadow: 0 4px 8px rgba(0,0,0,0.1);
    }
    .alternative-response {
        background-color: #e8f4fd;
        padding: 0.5rem;
        border-radius: 0.25rem;
        margin: 0.5rem 0;
        cursor: pointer;
        border-left: 4px solid #1f77b4;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }
    .selected-response {
        background-color: #d4edda;
        border-left: 4px solid #28a745;
        box-shadow: 0 4px 8px rgba(0,0,0,0.15);
    }
    .logo-container {
        display: flex;
        align-items: center;
        gap: 1rem;
        margin-bottom: 2rem;
    }
    .logo-image {
        width: 60px;
        height: 60px;
        object-fit: contain;
    }
    /* Text input gÃ¶lgeleri */
    .stTextInput > div > div > input {
        box-shadow: 0 4px 8px rgba(0,0,0,0.15) !important;
        border-radius: 4px !important;
    }
    /* Text area gÃ¶lgeleri - daha spesifik */
    .stTextArea textarea {
        box-shadow: 0 6px 12px rgba(0,0,0,0.2) !important;
        border-radius: 6px !important;
        padding: 12px !important;
    }
    /* Text area container'larÄ± iÃ§in gÃ¶lge */
    .stTextArea > div {
        box-shadow: 0 6px 12px rgba(0,0,0,0.2) !important;
        border-radius: 6px !important;
    }
    /* Text area'lar iÃ§in ek gÃ¶lge */
    .stTextArea > div > div > textarea {
        box-shadow: 0 6px 12px rgba(0,0,0,0.2) !important;
        border-radius: 6px !important;
    }
    /* Selectbox gÃ¶lgeleri */
    .stSelectbox > div > div > div {
        box-shadow: 0 4px 8px rgba(0,0,0,0.15) !important;
        border-radius: 4px !important;
    }
    /* Slider gÃ¶lgeleri */
    .stSlider > div > div > div {
        box-shadow: 0 4px 8px rgba(0,0,0,0.15) !important;
    }
    /* Expander gÃ¶lgeleri - daha spesifik */
    .stExpander {
        box-shadow: 0 6px 12px rgba(0,0,0,0.2) !important;
        border-radius: 8px !important;
        padding: 8px !important;
    }
    /* BaÅŸlÄ±k gÃ¶lgeleri */
    h1, h2, h3 {
        text-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }
    /* Logo gÃ¶lgesi */
    .stImage > img {
        box-shadow: 0 4px 8px rgba(0,0,0,0.15) !important;
    }
</style>
""", unsafe_allow_html=True)

def get_models():
    """Get available models from backend"""
    try:
        response = requests.get(f"{BACKEND_URL}/models")
        if response.status_code == 200:
            return response.json()
        else:
            st.error("Modeller yÃ¼klenemedi")
            return []
    except Exception as e:
        st.error(f"BaÄŸlantÄ± hatasÄ±: {e}")
        return []

def create_request(original_text):
    """Create a new request"""
    try:
        data = {
            "original_text": original_text,
            "response_type": "informative"  # Sabit deÄŸer
        }
        response = requests.post(f"{BACKEND_URL}/requests", json=data)
        if response.status_code == 200:
            return response.json()["id"]
        else:
            st.error("Request oluÅŸturulamadÄ±")
            return None
    except Exception as e:
        st.error(f"BaÄŸlantÄ± hatasÄ±: {e}")
        return None

def generate_response(request_id, custom_input, temperature, top_p, repetition_penalty, model_name):
    """Generate response using LLM"""
    try:
        # Sistem promptunu session state'den al
        system_prompt = st.session_state.get('system_prompt', '')
        
        data = {
            "request_id": request_id,
            "model_name": model_name,
            "custom_input": custom_input,
            "citizen_name": "",  # BoÅŸ bÄ±rakÄ±lÄ±yor, sadece "SayÄ±n" yazacak
            "temperature": temperature,
            "top_p": top_p,
            "repetition_penalty": repetition_penalty,
            "system_prompt": system_prompt  # Sistem promptunu ekle
        }
        response = requests.post(f"{BACKEND_URL}/generate", json=data)
        if response.status_code == 200:
            return response.json()
        else:
            st.error("YanÄ±t Ã¼retilirken hata oluÅŸtu")
            return None
    except Exception as e:
        st.error(f"BaÄŸlantÄ± hatasÄ±: {e}")
        return None

def update_response_feedback(response_id, is_selected=False, copied=False):
    """Update response feedback"""
    try:
        data = {
            "response_id": response_id,
            "is_selected": is_selected,
            "copied": copied
        }
        response = requests.post(f"{BACKEND_URL}/responses/feedback", json=data)
        return response.status_code == 200
    except Exception as e:
        st.error(f"Geri bildirim gÃ¼ncellenemedi: {e}")
        return False

# Ana uygulama
def main():
    # Logo ve baÅŸlÄ±k
    col_logo, col_title = st.columns([1, 4])
    
    with col_logo:
        st.image("logo.png", width=60)
    
    with col_title:
        st.title("AI YardÄ±mcÄ± - Bursa NilÃ¼fer Belediyesi")
    
    # AÃ§Ä±klama yazÄ±sÄ± baÅŸlÄ±ÄŸÄ±n altÄ±nda
    st.markdown("<div style='text-align: center; color: #333; font-size: 16px; font-weight: bold; margin: 10px 0;'>VatandaÅŸ taleplerine resmi yanÄ±tlar hazÄ±rlayÄ±n</div>", unsafe_allow_html=True)
    
    # Session state baÅŸlatma
    if 'responses' not in st.session_state:
        st.session_state.responses = []
    if 'current_response' not in st.session_state:
        st.session_state.current_response = None
    if 'generated_response' not in st.session_state:
        st.session_state.generated_response = None
    
    # Modelleri al
    models = get_models()
    
    # Sistem promptu dÃ¼zenlenebilir alan
    st.subheader("ğŸ”§ Sistem Promptu (Debug)")
    default_system_prompt = """Sen Bursa NilÃ¼fer Belediyesi Ã§alÄ±ÅŸanÄ±sÄ±n. VatandaÅŸlara resmi, kibar ve anlaÅŸÄ±lÄ±r yanÄ±tlar veriyorsun.

Sen Bursa NilÃ¼fer Belediyesi'nde Ã§alÄ±ÅŸan bir memursun.

GÃ¶revin, vatandaÅŸlardan gelen talepleri dikkatle okuyarak onlara resmi, anlaÅŸÄ±lÄ±r, kibar ve TÃ¼rkÃ§e bir dille yazÄ±lÄ± yanÄ±tlar oluÅŸturmaktÄ±r.

YanÄ±tÄ±n yapÄ±sÄ± ÅŸu ÅŸekilde olmalÄ±dÄ±r:
1. "SayÄ±n" ifadesiyle baÅŸlamalÄ±dÄ±r.
2. VatandaÅŸÄ±n ilettiÄŸi konuyu resmi bir ÅŸekilde Ã¶zetlemelisin.
3. Personelin hazÄ±rladÄ±ÄŸÄ± cevabÄ± daha uygun, nezaketli ve aÃ§Ä±klayÄ±cÄ± bir dile dÃ¶nÃ¼ÅŸtÃ¼rmelisin.
4. Metni "SaygÄ±larÄ±mÄ±zla, Bursa NilÃ¼fer Belediyesi" ifadesiyle bitirmelisin."""

    # KaydedilmiÅŸ prompt dosyasÄ±nÄ± kontrol et
    prompt_file = "saved_system_prompt.txt"
    
    # Session state'den sistem promptunu al veya dosyadan oku
    if 'system_prompt' not in st.session_state:
        if os.path.exists(prompt_file):
            try:
                with open(prompt_file, 'r', encoding='utf-8') as f:
                    st.session_state.system_prompt = f.read()
            except:
                st.session_state.system_prompt = default_system_prompt
        else:
            st.session_state.system_prompt = default_system_prompt

    system_prompt = st.text_area(
        "Sistem Promptu (LLM'e gÃ¶nderilen talimat):",
        value=st.session_state.system_prompt,
        height=100,
        help="Bu prompt LLM'e gÃ¶nderilir. DeÄŸiÅŸtirerek farklÄ± yanÄ±t stilleri deneyebilirsiniz. Ctrl+Enter ile kaydedin."
    )
    
    # Prompt deÄŸiÅŸtiÄŸinde session state'i ve dosyayÄ± gÃ¼ncelle
    if system_prompt != st.session_state.system_prompt:
        st.session_state.system_prompt = system_prompt
        try:
            with open(prompt_file, 'w', encoding='utf-8') as f:
                f.write(system_prompt)
            st.success("âœ… Sistem promptu kalÄ±cÄ± olarak kaydedildi!")
        except Exception as e:
            st.error(f"âŒ Kaydetme hatasÄ±: {e}")
    
    # Model seÃ§imi yanÄ±t ayarlarÄ± iÃ§inde olacak
    selected_model = "gemini-2.5-flash"  # VarsayÄ±lan model
    
    # Son Ã¼retilen yanÄ±t gÃ¶sterimi (baÅŸlÄ±ÄŸÄ±n hemen altÄ±nda)
    if st.session_state.generated_response:
        st.markdown("---")
        st.subheader("âœ… Son Ãœretilen YanÄ±t")
        
        response = st.session_state.generated_response
        response_text = response.get('response_text', '')
        latency_ms = response.get('latency_ms', 0)
        created_at = response.get('created_at', '')
        
        # YanÄ±t kutusu
        st.markdown(f"""
        <div class="response-box">
            <p>{response_text.replace(chr(10), '<br>')}</p>
            <small>â±ï¸ SÃ¼re: {latency_ms:.0f}ms | ğŸ“… {created_at}</small>
        </div>
        """, unsafe_allow_html=True)
        
        # Alternatif yanÄ±tlar ve aksiyonlar (Ã¼stte)
        if st.session_state.current_response:
            st.markdown("---")
            st.subheader("ğŸ”„ Alternatif YanÄ±tlar")
            
            # Aksiyon butonlarÄ±
            col_alt, col_select = st.columns(2)
            
            with col_alt:
                if st.button("ğŸ”„ Alternatif Ãœret") and len(st.session_state.responses) < 5:
                    st.info("Alternatif yanÄ±t Ã¼retiliyor...")
                    # Yeni alternatif Ã¼ret - tÃ¼m deÄŸiÅŸkenleri session_state'den al
                    if ('last_custom_input' in st.session_state and 
                        'last_temperature' in st.session_state and
                        'last_top_p' in st.session_state and
                        'last_repetition_penalty' in st.session_state and
                        'last_model_name' in st.session_state):
                        
                        new_response = generate_response(
                            st.session_state.current_response['request_id'], 
                            st.session_state.last_custom_input, 
                            st.session_state.last_temperature,
                            st.session_state.last_top_p,
                            st.session_state.last_repetition_penalty,
                            st.session_state.last_model_name
                        )
                        if new_response:
                            st.session_state.responses.append(new_response)
                            st.session_state.current_response = new_response
                            st.session_state.generated_response = new_response
                            st.rerun()
                    else:
                        st.error("Ã–nce bir yanÄ±t Ã¼retin")
                elif len(st.session_state.responses) >= 5:
                    st.warning("Maksimum 5 alternatif Ã¼retildi")
            
            with col_select:
                if st.button("âœ… SeÃ§ ve Kopyala"):
                    # YanÄ±tÄ± panoya kopyala
                    st.write("YanÄ±t panoya kopyalandÄ± ve seÃ§ildi!")
                    update_response_feedback(st.session_state.current_response['id'], is_selected=True, copied=True)
                    st.success("YanÄ±t seÃ§ildi ve kopyalandÄ±!")
        
        # Ã–nceki yanÄ±tlar (alternatif yanÄ±tlarÄ±n altÄ±nda)
        if len(st.session_state.responses) > 1:
            st.markdown("---")
            st.subheader("ğŸ“š Ã–nceki YanÄ±tlar")
            
            for i, resp in enumerate(st.session_state.responses[:-1]):  # Son yanÄ±t hariÃ§
                with st.expander(f"YanÄ±t #{i+1} - {resp.get('created_at', '')}"):
                    st.write(resp.get('response_text', ''))
                    st.caption(f"â±ï¸ {resp.get('latency_ms', 0):.0f}ms")
                    
                    # Eski yanÄ±tlar iÃ§in de seÃ§ butonu
                    if st.button(f"âœ… SeÃ§ ve Kopyala #{i+1}", key=f"select_old_{i}"):
                        st.write("YanÄ±t panoya kopyalandÄ± ve seÃ§ildi!")
                        update_response_feedback(resp['id'], is_selected=True, copied=True)
                        st.success(f"YanÄ±t #{i+1} seÃ§ildi ve kopyalandÄ±!")
    
    # Ä°ki sÃ¼tunlu layout
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("ğŸ“ Gelen Ä°stek/Ã–neri")
        original_text = st.text_area(
            "Gelen istek/Ã¶neri metnini buraya yapÄ±ÅŸtÄ±rÄ±n:",
            value="Bursa NilÃ¼fer'de bir dÃ¼kkanÄ±m var ve yÃ¶netim planÄ±ndan tahsisli otoparkÄ±mda bulunan dubalarÄ±, belediye ekipleri mafyavari ÅŸekilde tahsisli alanÄ±mdan alÄ±p gÃ¶tÃ¼rebiliyor. Geri aradÄ±ÄŸÄ±mda ise belediye zabÄ±tasÄ±, gÃ¶revliyi mahkemeye vermemi sÃ¶ylÃ¼yor. Bu nasÄ±l bir hizmet anlayÄ±ÅŸÄ±? Benim tahsisli alanÄ±mdan eÅŸyamÄ± alÄ±yorsunuz, buna ne denir? Herkes biliyordur. Bir yeri koruduÄŸunu zannedip baÅŸka bir yeri maÄŸdur etmek mi belediyecilik?",
            height=200
        )
    
    with col2:
        st.subheader("âœï¸ HazÄ±rladÄ±ÄŸÄ±nÄ±z Cevap")
        custom_input = st.text_area(
            "HazÄ±rladÄ±ÄŸÄ±nÄ±z cevap taslaÄŸÄ±nÄ± buraya yazÄ±n:",
            value="OrasÄ± size tahsis edilmiÅŸ bir yer deÄŸil. NilÃ¼fer halkÄ±nÄ±n ortak kullanÄ±m alanÄ±. KaldÄ±rÄ±mlar da Ã¶yle.",
            height=200
        )
    
    # LLM parametreleri - tam geniÅŸlik (kolonlarÄ±n dÄ±ÅŸÄ±nda)
    st.markdown("---")
    with st.expander("ğŸ”§ YanÄ±t AyarlarÄ±", expanded=False):
        # Model seÃ§imi (Ã¼stte)
        if models:
            # Sadece belirli modelleri gÃ¶ster
            allowed_models = [
                "gemini-2.5-flash",
                "gemini-1.5-flash-002", 
                "gemini-2.0-flash-001",
                "gpt-oss:latest"
            ]
            
            # Mevcut modellerden sadece izin verilenleri filtrele
            filtered_models = [model for model in models if model["name"] in allowed_models]
            
            if filtered_models:
                model_names = [model["name"] for model in filtered_models]
                selected_model = st.selectbox(
                    "ğŸ¤– Model SeÃ§imi:",
                    model_names,
                    index=0,  # Ä°lk model (gemini-2.5-flash) varsayÄ±lan olarak seÃ§ili
                    format_func=lambda x: next((m["display_name"] for m in filtered_models if m["name"] == x), x),
                    help="Kullanmak istediÄŸiniz AI modelini seÃ§in"
                )
            else:
                selected_model = "gemini-2.5-flash"  # Fallback
                st.warning("âš ï¸ Ä°zin verilen modeller bulunamadÄ±, varsayÄ±lan model kullanÄ±lÄ±yor")
        else:
            selected_model = "gemini-2.5-flash"  # Fallback
            st.warning("âš ï¸ Modeller yÃ¼klenemedi, varsayÄ±lan model kullanÄ±lÄ±yor")
        
        st.markdown("---")  # AyÄ±rÄ±cÄ± Ã§izgi
        
        # LLM parametreleri
        col1, col2, col3 = st.columns(3)
        
        with col1:
            temperature = st.slider(
                "ğŸŒ¡ï¸ Temperature", 
                min_value=0.0, 
                max_value=2.0, 
                value=st.session_state.get('last_temperature', 0.5), 
                step=0.1,
                help="DÃ¼ÅŸÃ¼k deÄŸerler daha tutarlÄ±, yÃ¼ksek deÄŸerler daha yaratÄ±cÄ± yanÄ±tlar Ã¼retir"
            )
        
        with col2:
            top_p = st.slider(
                "ğŸ¯ Top-p", 
                min_value=0.0, 
                max_value=1.0, 
                value=st.session_state.get('last_top_p', 0.4), 
                step=0.1,
                help="Kelime seÃ§iminde Ã§eÅŸitliliÄŸi kontrol eder. DÃ¼ÅŸÃ¼k deÄŸerler daha odaklÄ± yanÄ±tlar Ã¼retir"
            )
        
        with col3:
            repetition_penalty = st.slider(
                "ğŸ”„ Repetition Penalty", 
                min_value=0.0, 
                max_value=3.0, 
                value=st.session_state.get('last_repetition_penalty', 2.0), 
                step=0.1,
                help="Tekrarlanan kelimeleri azaltÄ±r. YÃ¼ksek deÄŸerler daha Ã§eÅŸitli kelime kullanÄ±mÄ±nÄ± saÄŸlar"
            )
        
        # Parametreleri kaydetme dosyasÄ±
        llm_params_file = "saved_llm_params.json"
        
        # VarsayÄ±lan deÄŸerler
        default_params = {
            "temperature": 0.5,
            "top_p": 0.4,
            "repetition_penalty": 2.0
        }
        
        # KaydedilmiÅŸ parametreleri yÃ¼kle
        if os.path.exists(llm_params_file):
            try:
                with open(llm_params_file, 'r', encoding='utf-8') as f:
                    saved_params = json.load(f)
                    # Eksik parametreler iÃ§in varsayÄ±lan deÄŸerleri kullan
                    for key, default_value in default_params.items():
                        if key not in saved_params:
                            saved_params[key] = default_value
            except:
                saved_params = default_params
        else:
            saved_params = default_params
        
        # Parametreler deÄŸiÅŸtiÄŸinde kaydet
        current_params = {
            "temperature": temperature,
            "top_p": top_p,
            "repetition_penalty": repetition_penalty
        }
        
        if current_params != saved_params:
            try:
                with open(llm_params_file, 'w', encoding='utf-8') as f:
                    json.dump(current_params, f, indent=2, ensure_ascii=False)
                st.success("âœ… LLM parametreleri kaydedildi!")
            except Exception as e:
                st.error(f"âŒ Kaydetme hatasÄ±: {e}")
    
    # YanÄ±t Ã¼ret butonu
    if st.button("ğŸš€ YanÄ±t Ãœret", type="primary"):
        if original_text and custom_input:
            with st.spinner("YanÄ±t Ã¼retiliyor..."):
                # Request oluÅŸtur
                request_id = create_request(original_text)
                
                if request_id:
                    # DeÄŸiÅŸkenleri session_state'e kaydet
                    st.session_state.last_custom_input = custom_input
                    st.session_state.last_temperature = temperature
                    st.session_state.last_top_p = top_p
                    st.session_state.last_repetition_penalty = repetition_penalty
                    st.session_state.last_model_name = selected_model
                    
                    # YanÄ±t Ã¼ret
                    response_data = generate_response(
                        request_id, custom_input, 
                        temperature, top_p, repetition_penalty, selected_model
                    )
                    
                    if response_data:
                        st.session_state.current_response = response_data
                        st.session_state.responses.append(response_data)
                        st.session_state.generated_response = response_data
                        st.success("âœ… YanÄ±t baÅŸarÄ±yla Ã¼retildi!")
                        st.rerun()
                    else:
                        st.error("âŒ YanÄ±t Ã¼retilemedi")
                else:
                    st.error("âŒ Request oluÅŸturulamadÄ±")
        else:
            st.warning("âš ï¸ LÃ¼tfen gerekli alanlarÄ± doldurun")

if __name__ == "__main__":
    main() 